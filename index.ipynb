{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Methods - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you have some preliminary background on bootstrapping, jackknife and permutation tests, its time to practice those skills by coding them into functions. You'll then apply these tests to a hypothesis test and compare the results to a parametric t-test.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Understand permutation testing\n",
    "* Understand what jackknife is\n",
    "* Understand what bootstrapping is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "\n",
    "Write a function that takes a sample and generates n additional samples of the same size using bootstrapping. (Recall that bootstrapping creates additional sets by sampling with replacement.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1, 1, 4], [1, 3, 3, 1], [1, 3, 3, 3]]\n"
     ]
    }
   ],
   "source": [
    "def bootstrap(data, n):\n",
    "    #Your code here\n",
    "    bs = []\n",
    "    for i in range(n):\n",
    "        bs.append(choices(data, k=len(data)))\n",
    "    return bs\n",
    "# test code\n",
    "print(bootstrap([1,2,3,4],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jackknife \n",
    "\n",
    "Write a function that creates additional samples by removing one element at a time. The function should do this for each of the n items in the original sample, returning n samples, each with n-1 members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 4], [1, 3, 4], [1, 2, 4], [1, 2, 3]]\n"
     ]
    }
   ],
   "source": [
    "def jack1(data):\n",
    "    \"\"\"This function should take in a list of n observations and return n lists\n",
    "    each with one member (presumably the nth) removed.\"\"\"\n",
    "    # Your code here\n",
    "    jk = []\n",
    "    for i in range(len(data)):\n",
    "        jk.append(data[:i] + data[i+1:])\n",
    "    return jk    \n",
    "#test code    \n",
    "print(jack1([1,2,3,4]))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Testing\n",
    "\n",
    "Define a function that generate all possible, equally sized, two set splits of two sets A and B. Sets A and B need not be the same size, but all of the generate two set splits should be of equal size. For example, if we had a set with 5 members and a set with 7 members, the function would return all possible 5-7 ordered splits of the 12 items. \n",
    "\n",
    "> Note that these are actually combinations! However, as noted previously, permutation tests really investigate possible regroupings of the data observations, so calculating combinations is a more efficient approach!\n",
    "\n",
    "\n",
    "Here's a more in depth example:  \n",
    "```python\n",
    ">>> A = [1,2,2]\n",
    ">>> B = [1,3]\n",
    ">>> combT(A, B) \n",
    "[([1,2,2], [1,3]),\n",
    " ([1,2,3], [1,2]),\n",
    " ([1,2,1], [2,3]),\n",
    " ([1,1,3], [2,2]),\n",
    " ([2,2,3], [1,1])]\n",
    "               \n",
    "```  \n",
    "These are all the possible 3-2 member splits of the 5 elements : 1,1,2,2,3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([1, 1, 3], [2, 2]), ([1, 2, 2], [1, 3]), ([1, 2, 3], [1, 2]), ([1, 1, 2], [2, 3]), ([2, 2, 3], [1, 1])]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def combT(a, b):\n",
    "    union = sorted(a + b)\n",
    "    all_combs = []\n",
    "    for x in set(combinations(union, len(a))):\n",
    "        union_copy = union.copy()\n",
    "        for y in x:\n",
    "            union_copy.remove(y)\n",
    "        all_combs.append((list(x), union_copy))\n",
    "    return all_combs\n",
    "# test\n",
    "print(combT([1,2,2],[1,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Testing in Practice\n",
    "Let's further investigate the scenario proposed in the previous lesson. Below are two samples A and B. The samples are mock data for the blood pressure of sample patients. The research study is looking to validate whether there is a statistical difference in the blood pressure of these two groups using a 5% significance level.  First, calculate the mean blood pressure of each of the two samples. Then, calculate the difference of these means. From there, use your `combT()` function, defined above, to generate all the possible combinations of the entire sample data into A-B splits of equivalent sizes as the original sets. For each of these combinations, calculate the mean blood pressure of the two groups and record the difference between these sample means. The full collection of the difference in means between these generated samples will serve as the denominator to calculate the p-value associated with the difference between the original sample means.\n",
    "\n",
    "For example, in our small handwritten example above:\n",
    "\n",
    "$\\mu_a = \\frac{1+2+2}{3} = \\frac{5}{3}$  \n",
    "and  \n",
    "$\\mu_b = \\frac{1+3}{2} = \\frac{4}{2} = 2$  \n",
    "\n",
    "Giving us\n",
    "\n",
    "$\\mu_a - \\mu_b = \\frac{5}{3} - 2 = \\frac{1}{2}$\n",
    "\n",
    "In comparison, for our various combinations we have:\n",
    "\n",
    "([1,2,2], [1,3]):  $\\mu_a - \\mu_b = \\frac{5}{3} - 2 = \\frac{1}{2}$  \n",
    "([1,2,3], [1,2]):  $\\mu_a - \\mu_b = 2 - \\frac{3}{2} = \\frac{1}{2}$  \n",
    "([1,2,1], [2,3]):  $\\mu_a - \\mu_b = \\frac{4}{3} - \\frac{5}{3} = -\\frac{1}{2}$  \n",
    "([1,1,3], [2,2]):  $\\mu_a - \\mu_b = \\frac{5}{3} - 2 = \\frac{1}{2}$  \n",
    "([2,2,3], [1,1]):  $\\mu_a - \\mu_b = \\frac{7}{3} - 1 = \\frac{4}{3}$  \n",
    "\n",
    "A standard hypothesis test for this scenario might be:\n",
    "\n",
    "$h_0: \\mu_a = \\mu_b$  \n",
    "$h_1: \\mu_a < \\mu_b$  \n",
    "  \n",
    "Thus comparing our sample difference to the differences of our possible combinations, we look at the number of experiments from our combinations space that were the same or greater then our sample statistic, divided by the total number of combinations. In this case, 4 out of 5 of the combination cases produced the same or greater differences in the two sample means. This value .8 is a strong indication that we cannot refute the null hypothesis for this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [109.6927759 , 120.27296943, 103.54012038, 114.16555857,\n",
    "       122.93336175, 110.9271756 , 114.77443758, 116.34159338,\n",
    "       112.66413025, 118.30562665, 132.31196515, 117.99000948]\n",
    "b = [123.98967482, 141.11969004, 117.00293412, 121.6419775 ,\n",
    "       123.2703033 , 123.76944385, 105.95249634, 114.87114479,\n",
    "       130.6878082 , 140.60768727, 121.95433026, 123.11996767,\n",
    "       129.93260914, 121.01049611]\n",
    "\n",
    "a_mu = np.mean(a)\n",
    "b_mu = np.mean(b)\n",
    "delta_mu = a_mu - b_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "combos = combT([1,2,2],[1,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# the larger sample set hung up my computer so I tested code with smaller sample set\n",
    "counts = 0\n",
    "for i in combos:\n",
    "    if (np.mean(i[0])-np.mean(i[1]))>=delta_mu:\n",
    "        counts+=1\n",
    "print(counts/len(combos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test Revisited\n",
    "\n",
    "The parametric statistical test equivalent to our permutation test above would be a t-test of the two groups. Perform a t-test on the same data above in order to calculate the p-value. How does this compare to the above results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from scipy import stats\n",
    "\"\"\" Calculate Welch's t statistic for two samples. \"\"\"\n",
    "def welch_t(a, b):\n",
    "    \n",
    "    n1 = len(a)\n",
    "    n2 = len(b)\n",
    "    s1 = np.var(a, ddof=1)\n",
    "    s2 = np.var(b, ddof=1)\n",
    "    x1 = np.mean(a)\n",
    "    x2 = np.mean(b)\n",
    "    \n",
    "    num = abs(x1-x2)\n",
    "    denom = np.sqrt((s1/n1)+(s2/n2))\n",
    "        \n",
    "    return num/denom\n",
    "\n",
    "\"\"\" Calculate the effective degrees of freedom for two samples. \"\"\"\n",
    "def welch_df(a, b):\n",
    "    s1 = np.var(a, ddof=1)\n",
    "    s2 = np.var(b, ddof=1)\n",
    "    n1 = len(a)\n",
    "    n2 = len(b)\n",
    "    v1 = n1-1\n",
    "    v2 = n2-1\n",
    "    \n",
    "    num = ((s1/n1)+(s2/n2))**2\n",
    "    denom = (s1**2/((n1**2)*v1))+(s2**2/((n2**2)*v2))\n",
    "    \n",
    "    return num/denom\n",
    "\n",
    "# Returns p-value for welch's t\n",
    "def p_value(a, b, two_sided=False):\n",
    "    t = welch_t(a,b)\n",
    "    df = welch_df(a,b)\n",
    "    p = 1-stats.t.cdf(t,df)\n",
    "    \n",
    "    if two_sided:\n",
    "        p = p*2\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02079400974179224\n"
     ]
    }
   ],
   "source": [
    "print(p_value(a, b, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-2.475967750872386, pvalue=0.020794009741792126)\n"
     ]
    }
   ],
   "source": [
    "print(stats.ttest_ind(a, b, axis=0, equal_var=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just discovered that the scipy stats independent t-test is welch's t-test when equal_var=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-2.4279196935987, pvalue=0.023053215321495863)\n"
     ]
    }
   ],
   "source": [
    "print(stats.ttest_ind(a, b, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6196331755824978\n"
     ]
    }
   ],
   "source": [
    "num = np.mean(a) - np.mean(b)\n",
    "s = np.var(a+b)\n",
    "n = len(a+b)\n",
    "denom = s/np.sqrt(n)\n",
    "t = num / denom\n",
    "pval = stats.t.sf(np.abs(t), n-1)*2\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Applied\n",
    "\n",
    "Use your code above to apply the bootstrap technique to this hypothesis testing scenario. In other words, similar to the permutation testing you performed above, compute additional samples (arbitrarily let's say 1000) of the same size as the original sample, with replacement. For each of these additional samples, compute whether the difference in sample means is the same or greater then that of the original samples. Use this to calculate an overall p-value for the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "experiments = 1000\n",
    "counts = 0\n",
    "for i in range(experiments):\n",
    "    ai = bootstrap(a,1)\n",
    "    bi = bootstrap(b,1)\n",
    "    \n",
    "    if (np.mean(ai)-np.mean(bi))>=delta_mu:\n",
    "        counts+=1\n",
    "print(counts/experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-2.4279196935986955, 0.02305321532149608, 24.0)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "print(sm.stats.ttest_ind(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! In this lab you practice coding modern statistical resampling techniques of the 20th century! You also started to compare these non-parametric methods to other parametric methods such as the t-test that we previously discussed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
